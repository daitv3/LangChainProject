{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68e21aa1",
   "metadata": {},
   "source": [
    "# Evaluating Agents\n",
    "\n",
    "We have an email assistant that uses a router to triage emails and then passes the email to the agent for response generation. How can we be sure that it will work well in production? This is why testing is important: it guides our decisions about our agent architecture with quantifiable metrics like response quality, token usage, latency, or triage accuracy. [LangSmith](https://docs.smith.langchain.com/) offers two primary ways to test agents. \n",
    "\n",
    "![overview-img](img/overview_eval.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7f7048",
   "metadata": {},
   "source": [
    "#### Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c47d4c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2005c34d",
   "metadata": {},
   "source": [
    "## How to run Evaluations\n",
    "\n",
    "#### Pytest / Vitest\n",
    "\n",
    "[Pytest](https://docs.pytest.org/en/stable/) and Vitest are well known to many developers as a powerful tools for writing tests within the Python and JavaScript ecosystems. LangSmith integrates with these frameworks to allow you to write and run tests that log results to LangSmith. For this notebook, we'll use Pytest.\n",
    "* Pytest is a great way to get started for developers who are already familiar with their framework. \n",
    "* Pytest is great for more complex evaluations, where each agent test case requires specific checks and success criteria that are harder to generalize.\n",
    "\n",
    "#### LangSmith Datasets \n",
    "\n",
    "You can also create a dataset [in LangSmith](https://docs.smith.langchain.com/evaluation) and run our assistant against the dataset using the LangSmith evaluate API.\n",
    "* LangSmith datasets are great for teams who are collaboratively building out their test suite. \n",
    "* You can leverage production traces, annotation queues, synthetic data generation, and more, to add examples to an ever-growing golden dataset.\n",
    "* LangSmith datasets are great when you can define evaluators that can be applied to every test case in the dataset (ex. similarity, exact match accuracy, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b7c989",
   "metadata": {},
   "source": [
    "## Test Cases\n",
    "\n",
    "Testing often starts with defining the test cases, which can be a challenging process. In this case, we'll just define a set of example emails we want to handle along with a few things to test. You can see the test cases in `eval/email_dataset.py`, which contains the following:\n",
    "\n",
    "1. **Input Emails**: A collection of diverse email examples\n",
    "2. **Ground Truth Classifications**: `Respond`, `Notify`, `Ignore`\n",
    "3. **Expected Tool Calls**: Tools called for each email that requires a response\n",
    "4. **Response Criteria**: What makes a good response for emails requiring replies\n",
    "\n",
    "Note that we have both\n",
    "- End to end \"integration\" tests (e.g. Input Emails -> Agent -> Final Output vs Response Criteria)\n",
    "- Tests for specific steps in our workflow (e.g. Input Emails -> Agent -> Classification vs Ground Truth Classification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8fdc2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email Input: {'author': 'Alice Smith <alice.smith@company.com>', 'to': 'Lance Martin <lance@company.com>', 'subject': 'Quick question about API documentation', 'email_thread': \"Hi Lance,\\n\\nI was reviewing the API documentation for the new authentication service and noticed a few endpoints seem to be missing from the specs. Could you help clarify if this was intentional or if we should update the docs?\\n\\nSpecifically, I'm looking at:\\n- /auth/refresh\\n- /auth/validate\\n\\nThanks!\\nAlice\"}\n",
      "Expected Triage Output: respond\n",
      "Expected Tool Calls: ['write_email', 'done']\n",
      "Response Criteria: \n",
      "â€¢ Send email with write_email tool call to acknowledge the question and confirm it will be investigated  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from email_assistant.eval.email_dataset import email_inputs, expected_tool_calls, triage_outputs_list, response_criteria_list\n",
    "\n",
    "test_case_ix = 0\n",
    "\n",
    "print(\"Email Input:\", email_inputs[test_case_ix])\n",
    "print(\"Expected Triage Output:\", triage_outputs_list[test_case_ix])\n",
    "print(\"Expected Tool Calls:\", expected_tool_calls[test_case_ix])\n",
    "print(\"Response Criteria:\", response_criteria_list[test_case_ix])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2337bd7c",
   "metadata": {},
   "source": [
    "## Pytest Example\n",
    "\n",
    "Let's take a look at how we can write a test for a specific part of our workflow with Pytest. We will test whether our `email_assistant` makes the right tool calls when responding to the emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae92fe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "from email_assistant.eval.email_dataset import email_inputs, expected_tool_calls\n",
    "from email_assistant.utils import format_messages_string\n",
    "from email_assistant.email_assistant import email_assistant\n",
    "from email_assistant.utils import extract_tool_calls\n",
    "\n",
    "from langsmith import testing as t\n",
    "\n",
    "@pytest.mark.langsmith\n",
    "@pytest.mark.parametrize(\n",
    "    \"email_input, expected_calls\",\n",
    "    [   # Pick some examples with e-mail reply expected\n",
    "        (email_inputs[0],expected_tool_calls[0]),\n",
    "        (email_inputs[3],expected_tool_calls[3]),\n",
    "    ],\n",
    ")\n",
    "def test_email_dataset_tool_calls(email_input, expected_calls):\n",
    "    \"\"\"Test if email processing contains expected tool calls.\n",
    "    \n",
    "    This test confirms that all expected tools are called during email processing,\n",
    "    but does not check the order of tool invocations or the number of invocations\n",
    "    per tool. Additional checks for these aspects could be added if desired.\n",
    "    \"\"\"\n",
    "    # Run the email assistant\n",
    "    messages = [{\"role\": \"user\", \"content\": str(email_input)}]\n",
    "    result = email_assistant.invoke({\"messages\": messages})\n",
    "            \n",
    "    # Extract tool calls from messages list\n",
    "    extracted_tool_calls = extract_tool_calls(result['messages'])\n",
    "            \n",
    "    # Check if all expected tool calls are in the extracted ones\n",
    "    missing_calls = [call for call in expected_calls if call.lower() not in extracted_tool_calls]\n",
    "    \n",
    "    t.log_outputs({\n",
    "                \"missing_calls\": missing_calls,\n",
    "                \"extracted_tool_calls\": extracted_tool_calls,\n",
    "                \"response\": format_messages_string(result['messages'])\n",
    "            })\n",
    "\n",
    "    # Test passes if no expected calls are missing\n",
    "    assert len(missing_calls) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700aba2a",
   "metadata": {},
   "source": [
    "You'll notice a few things. \n",
    "- To [run with Pytest and log test results to LangSmith](https://docs.smith.langchain.com/evaluation/how_to_guides/pytest), we only need to add the `@pytest.mark.langsmith ` decorator to our function and place it in a file, as you see in `notebooks/test_tools.py`. This will log the test results to LangSmith.\n",
    "- Second, we can pass dataset examples to the test function as shown [here](https://docs.smith.langchain.com/evaluation/how_to_guides/pytest#parametrize-with-pytestmarkparametrize) via `@pytest.mark.parametrize`. \n",
    "\n",
    "#### Running Pytest\n",
    "We can run the test from the command line. We've defined the above code in a python file. From the project root, run:\n",
    "\n",
    "`! LANGSMITH_TEST_SUITE='Email assistant: Test Tools For Interrupt'  pytest notebooks/test_tools.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53165e98",
   "metadata": {},
   "source": [
    "#### Viewing Experiment Result\n",
    "\n",
    "We can view the results in the LangSmith UI. The `assert len(missing_calls) == 0` is logged to the `Pass` column in LangSmith. The `log_outputs` are passed to the `Outputs` column and function arguments are passed to the `Inputs` column. Each input passed in `@pytest.mark.parametrize(` is a separate row logged to the `LANGSMITH_TEST_SUITE` project name in LangSmith, which is found under `Datasets & Experiments`.\n",
    "\n",
    "![Test Results](img/test_result.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd325e27",
   "metadata": {},
   "source": [
    "## LangSmith Datasets Example\n",
    "\n",
    "![overview-img](img/eval_detail.png)\n",
    "\n",
    "Let's take a look at how we can run evaluations with LangSmith datasets. In the previous example with Pytest, we evaluated the tool calling accuracy of the email assistant. Now, the dataset that we're going to evaluate here is specifically for the triage step of the email assistant, in classifying whether an email requires a response.\n",
    "\n",
    "#### Dataset Definition \n",
    "\n",
    "We can [create a dataset in LangSmith](https://docs.smith.langchain.com/evaluation/how_to_guides/manage_datasets_programmatically#create-a-dataset) with the LangSmith SDK. The below code creates a dataset with the test cases in the `eval/email_dataset.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ea997ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "from email_assistant.eval.email_dataset import examples_triage\n",
    "\n",
    "# Initialize LangSmith client\n",
    "client = Client()\n",
    "\n",
    "# Dataset name\n",
    "dataset_name = \"E-mail Triage Evaluation\"\n",
    "\n",
    "# Create dataset if it doesn't exist\n",
    "if not client.has_dataset(dataset_name=dataset_name):\n",
    "    dataset = client.create_dataset(\n",
    "        dataset_name=dataset_name, \n",
    "        description=\"A dataset of e-mails and their triage decisions.\"\n",
    "    )\n",
    "    # Add examples to the dataset\n",
    "    client.create_examples(dataset_id=dataset.id, examples=examples_triage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2df606",
   "metadata": {},
   "source": [
    "#### Target Function\n",
    "\n",
    "The dataset has the following structure, with an e-mail input and a ground truth triage classification for the e-mail as output:\n",
    "\n",
    "```\n",
    "examples_triage = [\n",
    "  {\n",
    "      \"inputs\": {\"email_input\": email_input_1},\n",
    "      \"outputs\": {\"classification\": triage_output_1},   # NOTE: This becomes the reference_output in the created dataset\n",
    "  }, ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7d7e83f-3006-4386-9230-786545c7b1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Example Input (inputs): {'email_input': {'author': 'Alice Smith <alice.smith@company.com>', 'to': 'Lance Martin <lance@company.com>', 'subject': 'Quick question about API documentation', 'email_thread': \"Hi Lance,\\n\\nI was reviewing the API documentation for the new authentication service and noticed a few endpoints seem to be missing from the specs. Could you help clarify if this was intentional or if we should update the docs?\\n\\nSpecifically, I'm looking at:\\n- /auth/refresh\\n- /auth/validate\\n\\nThanks!\\nAlice\"}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Example Input (inputs):\", examples_triage[0]['inputs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f292f070-7af6-4370-9338-e90bfd6b3d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Example Reference Output (reference_outputs): {'classification': 'respond'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Example Reference Output (reference_outputs):\", examples_triage[0]['outputs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8290e820",
   "metadata": {},
   "source": [
    "We define a function that takes the dataset inputs and passes them to our email assistant. The LangSmith [evaluate API](https://docs.smith.langchain.com/evaluation) passes the `inputs` dict to this function. This function then returns a dict with the agent's output. Because we are evaluating the triage step, we only need to return the classification decision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b9d1ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_email_assistant(inputs: dict) -> dict:\n",
    "    \"\"\"Process an email through the workflow-based email assistant.\"\"\"\n",
    "    response = email_assistant.nodes['triage_router'].invoke({\"email_input\": inputs[\"email_input\"]})\n",
    "    return {\"classification_decision\": response.update['classification_decision']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba6ec4c",
   "metadata": {},
   "source": [
    "#### Evaluator Function \n",
    "\n",
    "Now, we create an evaluator function. What do we want to evaluate? We have reference outputs in our dataset and agent outputs defined in the functions above.\n",
    "\n",
    "* Reference outputs: `\"reference_outputs\": {\"classification\": triage_output_1} ...`\n",
    "* Agent outputs: `\"outputs\": {\"classification_decision\": agent_output_1} ...`\n",
    "\n",
    "We want to evaluate if the agent's output matches the reference output. So we simply need a an evaluator function that compares the two, where `outputs` is the agent's output and `reference_outputs` is the reference output from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fee7532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_evaluator(outputs: dict, reference_outputs: dict) -> bool:\n",
    "    \"\"\"Check if the answer exactly matches the expected answer.\"\"\"\n",
    "    return outputs[\"classification_decision\"].lower() == reference_outputs[\"classification\"].lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fd2de9",
   "metadata": {},
   "source": [
    "### Running Evaluation\n",
    "\n",
    "Now, the question is: how are these things hooked together? The evaluate API takes care of it for us. It passes the `inputs` dict from our dataset the target function. It passes the `reference_outputs` dict from our dataset to the evaluator function. And it passes the `outputs` of our agent to the evaluator function. \n",
    "\n",
    "Note this is similar to what we did with Pytest: in Pytest, we passed in the dataset example inputs and reference outputs to the test function with `@pytest.mark.parametrize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6807306d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'E-mail assistant workflow-a0260801' at:\n",
      "https://eu.smith.langchain.com/o/8eb3a7f0-e5b4-4177-a98f-99d616319bf7/datasets/d9a6b118-8834-42fd-bec1-142ec223dac2/compare?selectedSessions=81fb1336-e220-42b4-b474-3836f4abac9b\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9308b51ba32e4a24b639bde2718c36bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\pydantic\\v1\\main.py:1054: UserWarning: LangSmith now uses UUID v7 for run and trace identifiers. This warning appears when passing custom IDs. Please use: from langsmith import uuid7\n",
      "            id = uuid7()\n",
      "Future versions will require UUID v7.\n",
      "  input_data = validator(cls_, input_data)\n",
      "Error running target function: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}}\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1923, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\1330990688.py\", line 3, in target_email_assistant\n",
      "    response = email_assistant.nodes['triage_router'].invoke({\"email_input\": inputs[\"email_input\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_read.py\", line 233, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py\", line 400, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\src\\email_assistant\\email_assistant.py\", line 116, in triage_router\n",
      "    result = llm_router.invoke(\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3127, in invoke\n",
      "    input_ = context.run(step.invoke, input_, config, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5534, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 385, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1104, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 914, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1208, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1333, in _generate\n",
      "    raise e\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1301, in _generate\n",
      "    self.root_client.chat.completions.with_raw_response.parse(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 184, in parse\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}}\n",
      "Error running evaluator <DynamicRunEvaluator classification_evaluator> on run 019a91a8-8c65-748b-8333-7d33b5523665: KeyError('classification_decision')\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1619, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\3876906441.py\", line 3, in classification_evaluator\n",
      "    return outputs[\"classification_decision\"].lower() == reference_outputs[\"classification\"].lower()\n",
      "           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyError: 'classification_decision'\n",
      "Error running target function: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1923, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\1330990688.py\", line 3, in target_email_assistant\n",
      "    response = email_assistant.nodes['triage_router'].invoke({\"email_input\": inputs[\"email_input\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_read.py\", line 233, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py\", line 400, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\src\\email_assistant\\email_assistant.py\", line 116, in triage_router\n",
      "    result = llm_router.invoke(\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3127, in invoke\n",
      "    input_ = context.run(step.invoke, input_, config, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5534, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 385, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1104, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 914, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1208, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1333, in _generate\n",
      "    raise e\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1301, in _generate\n",
      "    self.root_client.chat.completions.with_raw_response.parse(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 184, in parse\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error running evaluator <DynamicRunEvaluator classification_evaluator> on run 019a91a8-8c65-748b-8333-7d34953e294e: KeyError('classification_decision')\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1619, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\3876906441.py\", line 3, in classification_evaluator\n",
      "    return outputs[\"classification_decision\"].lower() == reference_outputs[\"classification\"].lower()\n",
      "           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyError: 'classification_decision'\n",
      "Error running target function: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}}\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1923, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\1330990688.py\", line 3, in target_email_assistant\n",
      "    response = email_assistant.nodes['triage_router'].invoke({\"email_input\": inputs[\"email_input\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_read.py\", line 233, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py\", line 400, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\src\\email_assistant\\email_assistant.py\", line 116, in triage_router\n",
      "    result = llm_router.invoke(\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3127, in invoke\n",
      "    input_ = context.run(step.invoke, input_, config, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5534, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 385, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1104, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 914, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1208, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1333, in _generate\n",
      "    raise e\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1301, in _generate\n",
      "    self.root_client.chat.completions.with_raw_response.parse(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 184, in parse\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}}\n",
      "Error running evaluator <DynamicRunEvaluator classification_evaluator> on run 019a91a8-8e6c-7430-b71d-bbfa8d90b3fc: KeyError('classification_decision')\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1619, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\3876906441.py\", line 3, in classification_evaluator\n",
      "    return outputs[\"classification_decision\"].lower() == reference_outputs[\"classification\"].lower()\n",
      "           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyError: 'classification_decision'\n",
      "Error running target function: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}}\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1923, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\1330990688.py\", line 3, in target_email_assistant\n",
      "    response = email_assistant.nodes['triage_router'].invoke({\"email_input\": inputs[\"email_input\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_read.py\", line 233, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py\", line 400, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\src\\email_assistant\\email_assistant.py\", line 116, in triage_router\n",
      "    result = llm_router.invoke(\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3127, in invoke\n",
      "    input_ = context.run(step.invoke, input_, config, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5534, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 385, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1104, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 914, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1208, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1333, in _generate\n",
      "    raise e\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1301, in _generate\n",
      "    self.root_client.chat.completions.with_raw_response.parse(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 184, in parse\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}}\n",
      "Error running evaluator <DynamicRunEvaluator classification_evaluator> on run 019a91a8-8e8e-74dc-9493-428aa194ad1e: KeyError('classification_decision')\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1619, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\3876906441.py\", line 3, in classification_evaluator\n",
      "    return outputs[\"classification_decision\"].lower() == reference_outputs[\"classification\"].lower()\n",
      "           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyError: 'classification_decision'\n",
      "Error running target function: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}}\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1923, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\1330990688.py\", line 3, in target_email_assistant\n",
      "    response = email_assistant.nodes['triage_router'].invoke({\"email_input\": inputs[\"email_input\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_read.py\", line 233, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py\", line 400, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\src\\email_assistant\\email_assistant.py\", line 116, in triage_router\n",
      "    result = llm_router.invoke(\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3127, in invoke\n",
      "    input_ = context.run(step.invoke, input_, config, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5534, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 385, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1104, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 914, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1208, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1333, in _generate\n",
      "    raise e\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1301, in _generate\n",
      "    self.root_client.chat.completions.with_raw_response.parse(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 184, in parse\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}}\n",
      "Error running evaluator <DynamicRunEvaluator classification_evaluator> on run 019a91a8-8f7c-70e7-9d85-24ab57487251: KeyError('classification_decision')\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1619, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\3876906441.py\", line 3, in classification_evaluator\n",
      "    return outputs[\"classification_decision\"].lower() == reference_outputs[\"classification\"].lower()\n",
      "           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyError: 'classification_decision'\n",
      "Error running target function: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1923, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\1330990688.py\", line 3, in target_email_assistant\n",
      "    response = email_assistant.nodes['triage_router'].invoke({\"email_input\": inputs[\"email_input\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_read.py\", line 233, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py\", line 400, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\src\\email_assistant\\email_assistant.py\", line 116, in triage_router\n",
      "    result = llm_router.invoke(\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3127, in invoke\n",
      "    input_ = context.run(step.invoke, input_, config, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5534, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 385, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1104, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 914, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1208, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1333, in _generate\n",
      "    raise e\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1301, in _generate\n",
      "    self.root_client.chat.completions.with_raw_response.parse(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 184, in parse\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error running evaluator <DynamicRunEvaluator classification_evaluator> on run 019a91a8-8f6f-77f4-85bd-94a708ff298e: KeyError('classification_decision')\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1619, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\3876906441.py\", line 3, in classification_evaluator\n",
      "    return outputs[\"classification_decision\"].lower() == reference_outputs[\"classification\"].lower()\n",
      "           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyError: 'classification_decision'\n",
      "Error running target function: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}}\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1923, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\1330990688.py\", line 3, in target_email_assistant\n",
      "    response = email_assistant.nodes['triage_router'].invoke({\"email_input\": inputs[\"email_input\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_read.py\", line 233, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py\", line 400, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\src\\email_assistant\\email_assistant.py\", line 116, in triage_router\n",
      "    result = llm_router.invoke(\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3127, in invoke\n",
      "    input_ = context.run(step.invoke, input_, config, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5534, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 385, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1104, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 914, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1208, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1333, in _generate\n",
      "    raise e\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1301, in _generate\n",
      "    self.root_client.chat.completions.with_raw_response.parse(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 184, in parse\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}}\n",
      "Error running evaluator <DynamicRunEvaluator classification_evaluator> on run 019a91a8-9074-753c-918a-ce3c5f73cbda: KeyError('classification_decision')\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1619, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\3876906441.py\", line 3, in classification_evaluator\n",
      "    return outputs[\"classification_decision\"].lower() == reference_outputs[\"classification\"].lower()\n",
      "           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyError: 'classification_decision'\n",
      "Error running target function: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1923, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\1330990688.py\", line 3, in target_email_assistant\n",
      "    response = email_assistant.nodes['triage_router'].invoke({\"email_input\": inputs[\"email_input\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_read.py\", line 233, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py\", line 400, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\src\\email_assistant\\email_assistant.py\", line 116, in triage_router\n",
      "    result = llm_router.invoke(\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3127, in invoke\n",
      "    input_ = context.run(step.invoke, input_, config, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5534, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 385, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1104, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 914, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1208, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1333, in _generate\n",
      "    raise e\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1301, in _generate\n",
      "    self.root_client.chat.completions.with_raw_response.parse(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 184, in parse\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error running evaluator <DynamicRunEvaluator classification_evaluator> on run 019a91a8-9089-73e8-a5ba-e706513186af: KeyError('classification_decision')\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1619, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\3876906441.py\", line 3, in classification_evaluator\n",
      "    return outputs[\"classification_decision\"].lower() == reference_outputs[\"classification\"].lower()\n",
      "           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyError: 'classification_decision'\n",
      "Error running target function: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}}\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1923, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\1330990688.py\", line 3, in target_email_assistant\n",
      "    response = email_assistant.nodes['triage_router'].invoke({\"email_input\": inputs[\"email_input\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_read.py\", line 233, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py\", line 400, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\src\\email_assistant\\email_assistant.py\", line 116, in triage_router\n",
      "    result = llm_router.invoke(\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3127, in invoke\n",
      "    input_ = context.run(step.invoke, input_, config, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5534, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 385, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1104, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 914, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1208, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1333, in _generate\n",
      "    raise e\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1301, in _generate\n",
      "    self.root_client.chat.completions.with_raw_response.parse(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 184, in parse\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}}\n",
      "Error running target function: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}}\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1923, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\1330990688.py\", line 3, in target_email_assistant\n",
      "    response = email_assistant.nodes['triage_router'].invoke({\"email_input\": inputs[\"email_input\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_read.py\", line 233, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py\", line 400, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\src\\email_assistant\\email_assistant.py\", line 116, in triage_router\n",
      "    result = llm_router.invoke(\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3127, in invoke\n",
      "    input_ = context.run(step.invoke, input_, config, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5534, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 385, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1104, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 914, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1208, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1333, in _generate\n",
      "    raise e\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1301, in _generate\n",
      "    self.root_client.chat.completions.with_raw_response.parse(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 184, in parse\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}}\n",
      "Error running evaluator <DynamicRunEvaluator classification_evaluator> on run 019a91a8-9170-7110-a980-bea0ef6df2aa: KeyError('classification_decision')\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1619, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\3876906441.py\", line 3, in classification_evaluator\n",
      "    return outputs[\"classification_decision\"].lower() == reference_outputs[\"classification\"].lower()\n",
      "           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyError: 'classification_decision'\n",
      "Error running evaluator <DynamicRunEvaluator classification_evaluator> on run 019a91a8-917d-7571-b5c7-ade6b8f2b467: KeyError('classification_decision')\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1619, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\3876906441.py\", line 3, in classification_evaluator\n",
      "    return outputs[\"classification_decision\"].lower() == reference_outputs[\"classification\"].lower()\n",
      "           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyError: 'classification_decision'\n",
      "Error running target function: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1923, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\1330990688.py\", line 3, in target_email_assistant\n",
      "    response = email_assistant.nodes['triage_router'].invoke({\"email_input\": inputs[\"email_input\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_read.py\", line 233, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py\", line 400, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\src\\email_assistant\\email_assistant.py\", line 116, in triage_router\n",
      "    result = llm_router.invoke(\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3127, in invoke\n",
      "    input_ = context.run(step.invoke, input_, config, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5534, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 385, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1104, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 914, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1208, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1333, in _generate\n",
      "    raise e\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1301, in _generate\n",
      "    self.root_client.chat.completions.with_raw_response.parse(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 184, in parse\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error running target function: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}}\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1923, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\1330990688.py\", line 3, in target_email_assistant\n",
      "    response = email_assistant.nodes['triage_router'].invoke({\"email_input\": inputs[\"email_input\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_read.py\", line 233, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py\", line 400, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\src\\email_assistant\\email_assistant.py\", line 116, in triage_router\n",
      "    result = llm_router.invoke(\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3127, in invoke\n",
      "    input_ = context.run(step.invoke, input_, config, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5534, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 385, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1104, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 914, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1208, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1333, in _generate\n",
      "    raise e\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1301, in _generate\n",
      "    self.root_client.chat.completions.with_raw_response.parse(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 184, in parse\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}}\n",
      "Error running evaluator <DynamicRunEvaluator classification_evaluator> on run 019a91a8-928a-76c3-8e1b-dd2580a031dc: KeyError('classification_decision')\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1619, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\3876906441.py\", line 3, in classification_evaluator\n",
      "    return outputs[\"classification_decision\"].lower() == reference_outputs[\"classification\"].lower()\n",
      "           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyError: 'classification_decision'\n",
      "Error running evaluator <DynamicRunEvaluator classification_evaluator> on run 019a91a8-927d-7266-af5c-eb31dcd095ee: KeyError('classification_decision')\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1619, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\3876906441.py\", line 3, in classification_evaluator\n",
      "    return outputs[\"classification_decision\"].lower() == reference_outputs[\"classification\"].lower()\n",
      "           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyError: 'classification_decision'\n",
      "Error running target function: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}}\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1923, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\1330990688.py\", line 3, in target_email_assistant\n",
      "    response = email_assistant.nodes['triage_router'].invoke({\"email_input\": inputs[\"email_input\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_read.py\", line 233, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py\", line 400, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\src\\email_assistant\\email_assistant.py\", line 116, in triage_router\n",
      "    result = llm_router.invoke(\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3127, in invoke\n",
      "    input_ = context.run(step.invoke, input_, config, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5534, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 385, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1104, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 914, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1208, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1333, in _generate\n",
      "    raise e\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1301, in _generate\n",
      "    self.root_client.chat.completions.with_raw_response.parse(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 184, in parse\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}}\n",
      "Error running target function: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1923, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\1330990688.py\", line 3, in target_email_assistant\n",
      "    response = email_assistant.nodes['triage_router'].invoke({\"email_input\": inputs[\"email_input\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_read.py\", line 233, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py\", line 400, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\src\\email_assistant\\email_assistant.py\", line 116, in triage_router\n",
      "    result = llm_router.invoke(\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3127, in invoke\n",
      "    input_ = context.run(step.invoke, input_, config, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5534, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 385, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1104, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 914, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1208, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1333, in _generate\n",
      "    raise e\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1301, in _generate\n",
      "    self.root_client.chat.completions.with_raw_response.parse(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 184, in parse\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error running evaluator <DynamicRunEvaluator classification_evaluator> on run 019a91a8-939b-71d6-ad63-fca95c889e9e: KeyError('classification_decision')\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1619, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\3876906441.py\", line 3, in classification_evaluator\n",
      "    return outputs[\"classification_decision\"].lower() == reference_outputs[\"classification\"].lower()\n",
      "           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyError: 'classification_decision'\n",
      "Error running evaluator <DynamicRunEvaluator classification_evaluator> on run 019a91a8-9394-7707-8027-bcd3569df272: KeyError('classification_decision')\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1619, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\3876906441.py\", line 3, in classification_evaluator\n",
      "    return outputs[\"classification_decision\"].lower() == reference_outputs[\"classification\"].lower()\n",
      "           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyError: 'classification_decision'\n",
      "Error running target function: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1923, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\1330990688.py\", line 3, in target_email_assistant\n",
      "    response = email_assistant.nodes['triage_router'].invoke({\"email_input\": inputs[\"email_input\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_read.py\", line 233, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py\", line 400, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\src\\email_assistant\\email_assistant.py\", line 116, in triage_router\n",
      "    result = llm_router.invoke(\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3127, in invoke\n",
      "    input_ = context.run(step.invoke, input_, config, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5534, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 385, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1104, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 914, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1208, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1333, in _generate\n",
      "    raise e\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1301, in _generate\n",
      "    self.root_client.chat.completions.with_raw_response.parse(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 184, in parse\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error running evaluator <DynamicRunEvaluator classification_evaluator> on run 019a91a8-9498-7338-95e0-e507347d1eb6: KeyError('classification_decision')\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1619, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\3876906441.py\", line 3, in classification_evaluator\n",
      "    return outputs[\"classification_decision\"].lower() == reference_outputs[\"classification\"].lower()\n",
      "           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyError: 'classification_decision'\n",
      "Error running target function: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}}\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1923, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\1330990688.py\", line 3, in target_email_assistant\n",
      "    response = email_assistant.nodes['triage_router'].invoke({\"email_input\": inputs[\"email_input\"]})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_read.py\", line 233, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py\", line 400, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\src\\email_assistant\\email_assistant.py\", line 116, in triage_router\n",
      "    result = llm_router.invoke(\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3127, in invoke\n",
      "    input_ = context.run(step.invoke, input_, config, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5534, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 385, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1104, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 914, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1208, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1333, in _generate\n",
      "    raise e\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 1301, in _generate\n",
      "    self.root_client.chat.completions.with_raw_response.parse(\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 184, in parse\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}}\n",
      "Error running evaluator <DynamicRunEvaluator classification_evaluator> on run 019a91a8-949a-7270-a516-2f86b1e5f5ae: KeyError('classification_decision')\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1619, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 704, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4048\\3876906441.py\", line 3, in classification_evaluator\n",
      "    return outputs[\"classification_decision\"].lower() == reference_outputs[\"classification\"].lower()\n",
      "           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyError: 'classification_decision'\n"
     ]
    }
   ],
   "source": [
    "# Set to true if you want to kick off evaluation\n",
    "run_expt = True\n",
    "if run_expt:\n",
    "    experiment_results_workflow = client.evaluate(\n",
    "        # Run agent \n",
    "        target_email_assistant,\n",
    "        # Dataset name   \n",
    "        data=dataset_name,\n",
    "        # Evaluator\n",
    "        evaluators=[classification_evaluator],\n",
    "        # Name of the experiment\n",
    "        experiment_prefix=\"E-mail assistant workflow\", \n",
    "        # Number of concurrent evaluations\n",
    "        max_concurrency=2, \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76baff88",
   "metadata": {},
   "source": [
    "We can view the results from both experiments in the LangSmith UI.\n",
    "\n",
    "![Test Results](img/eval.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5146b52",
   "metadata": {},
   "source": [
    "## LLM-as-Judge Evaluation\n",
    "\n",
    "We've shown unit tests for the triage step (using evaluate()) and tool calling (using Pytest). \n",
    "\n",
    "We'll showcase how you could use an LLM as a judge to evaluate our agent's execution against a set of success criteria. \n",
    "\n",
    "![types](img/eval_types.png)\n",
    "\n",
    "First, we define a structured output schema for our LLM grader that contains a grade and justification for the grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1d342b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "class CriteriaGrade(BaseModel):\n",
    "    \"\"\"Score the response against specific criteria.\"\"\"\n",
    "    justification: str = Field(description=\"The justification for the grade and score, including specific examples from the response.\")\n",
    "    grade: bool = Field(description=\"Does the response meet the provided criteria?\")\n",
    "    \n",
    "# Create a global LLM for evaluation to avoid recreating it for each test\n",
    "criteria_eval_llm = init_chat_model(base_url=\"https://aiportalapi.stu-platform.live/jpe\", model=\"openai:GPT-4o-mini\")\n",
    "criteria_eval_structured_llm = criteria_eval_llm.with_structured_output(CriteriaGrade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bec02b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email Input: {'author': 'Alice Smith <alice.smith@company.com>', 'to': 'Lance Martin <lance@company.com>', 'subject': 'Quick question about API documentation', 'email_thread': \"Hi Lance,\\n\\nI was reviewing the API documentation for the new authentication service and noticed a few endpoints seem to be missing from the specs. Could you help clarify if this was intentional or if we should update the docs?\\n\\nSpecifically, I'm looking at:\\n- /auth/refresh\\n- /auth/validate\\n\\nThanks!\\nAlice\"}\n",
      "Success Criteria: \n",
      "â€¢ Send email with write_email tool call to acknowledge the question and confirm it will be investigated  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "email_input = email_inputs[0]\n",
    "print(\"Email Input:\", email_input)\n",
    "success_criteria = response_criteria_list[0]\n",
    "print(\"Success Criteria:\", success_criteria)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38390ccd",
   "metadata": {},
   "source": [
    "Our Email Assistant is invoked with the email input and the response is formatted into a string. These are all then passed to the LLM grader to receive a grade and justification for the grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbff28fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m response = \u001b[43memail_assistant\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43memail_input\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43memail_input\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mF:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3050\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3047\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3048\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3050\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3051\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3052\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3053\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3054\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3055\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3056\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3057\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3058\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3059\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3060\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3061\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3062\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3063\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3064\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3065\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mF:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2633\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2631\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2632\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2633\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2634\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2635\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2636\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2637\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2638\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2639\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2640\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2641\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2642\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2643\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mF:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mF:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mF:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mF:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mF:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\src\\email_assistant\\email_assistant.py:116\u001b[39m, in \u001b[36mtriage_router\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m    113\u001b[39m email_markdown = format_email_markdown(subject, author, to, email_thread)\n\u001b[32m    115\u001b[39m \u001b[38;5;66;03m# Run the router LLM\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m result = \u001b[43mllm_router\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Decision\u001b[39;00m\n\u001b[32m    124\u001b[39m classification = result.classification\n",
      "\u001b[36mFile \u001b[39m\u001b[32mF:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3127\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3125\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3126\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3127\u001b[39m         input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3128\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3129\u001b[39m         input_ = context.run(step.invoke, input_, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mF:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5534\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5527\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5528\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5529\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5532\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5533\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5534\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5535\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5536\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5537\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5538\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mF:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:385\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    371\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    373\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    378\u001b[39m     **kwargs: Any,\n\u001b[32m    379\u001b[39m ) -> AIMessage:\n\u001b[32m    380\u001b[39m     config = ensure_config(config)\n\u001b[32m    381\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    382\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    383\u001b[39m         cast(\n\u001b[32m    384\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    395\u001b[39m         ).message,\n\u001b[32m    396\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mF:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1104\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1095\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1096\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1097\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1101\u001b[39m     **kwargs: Any,\n\u001b[32m   1102\u001b[39m ) -> LLMResult:\n\u001b[32m   1103\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1104\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mF:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:914\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    911\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    912\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    913\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m         )\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    922\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mF:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1208\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1206\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1207\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1208\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1209\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1212\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mF:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1333\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1331\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mhttp_response\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1332\u001b[39m         e.response = raw_response.http_response  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1333\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   1334\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1335\u001b[39m     \u001b[38;5;28mself\u001b[39m.include_response_headers\n\u001b[32m   1336\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1337\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1338\u001b[39m ):\n\u001b[32m   1339\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mF:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1301\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1298\u001b[39m payload.pop(\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1299\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1300\u001b[39m     raw_response = (\n\u001b[32m-> \u001b[39m\u001b[32m1301\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_raw_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1302\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\n\u001b[32m   1303\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1304\u001b[39m     )\n\u001b[32m   1305\u001b[39m     response = raw_response.parse()\n\u001b[32m   1306\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m openai.BadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mF:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_legacy_response.py:364\u001b[39m, in \u001b[36mto_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m extra_headers[RAW_RESPONSE_HEADER] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mF:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:184\u001b[39m, in \u001b[36mCompletions.parse\u001b[39m\u001b[34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, safety_identifier, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparser\u001b[39m(raw_completion: ChatCompletion) -> ParsedChatCompletion[ResponseFormatT]:\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[32m    179\u001b[39m         response_format=response_format,\n\u001b[32m    180\u001b[39m         chat_completion=raw_completion,\n\u001b[32m    181\u001b[39m         input_tools=chat_completion_tools,\n\u001b[32m    182\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_retention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_type_to_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `ChatCompletion` instance into a `ParsedChatCompletion`\u001b[39;49;00m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedChatCompletion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mF:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mF:\\01_Projects\\LangChain\\Agents\\agents-from-scratch\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-xqCiz*************JXkg. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
      "During task with name 'triage_router' and id 'ca7b0912-2d91-9b57-bc79-2f34b7fa7366'"
     ]
    }
   ],
   "source": [
    "response = email_assistant.invoke({\"email_input\": email_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64619fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from email_assistant.eval.prompts import RESPONSE_CRITERIA_SYSTEM_PROMPT\n",
    "\n",
    "all_messages_str = format_messages_string(response['messages'])\n",
    "eval_result = criteria_eval_structured_llm.invoke([\n",
    "        {\"role\": \"system\",\n",
    "            \"content\": RESPONSE_CRITERIA_SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\",\n",
    "            \"content\": f\"\"\"\\n\\n Response criteria: {success_criteria} \\n\\n Assistant's response: \\n\\n {all_messages_str} \\n\\n Evaluate whether the assistant's response meets the criteria and provide justification for your evaluation.\"\"\"}\n",
    "    ])\n",
    "\n",
    "eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64275647-6fdb-4bf3-806b-4dbc770cbd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_CRITERIA_SYSTEM_PROMPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7994952c",
   "metadata": {},
   "source": [
    "We can see that the LLM grader returns an eval result with a schema matching our `CriteriaGrade` base model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b44111d",
   "metadata": {},
   "source": [
    "## Running against a Larger Test Suite\n",
    "Now that we've seen how to evaluate our agent using Pytest and evaluate(), and seen an example of using an LLM as a judge, we can use evaluations over a bigger test suite to get a better sense of how our agent performs over a wider variety of examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9280d5ae-3070-4131-8763-454073176081",
   "metadata": {},
   "source": [
    "Let's run our email_assistant against a larger test suite.\n",
    "```\n",
    "! LANGSMITH_TEST_SUITE='Email assistant: Test Full Response Interrupt' LANGSMITH_EXPERIMENT='email_assistant' pytest tests/test_response.py --agent-module email_assistant\n",
    "```\n",
    "\n",
    "In `test_response.py`, you can see a few things. \n",
    "\n",
    "We pass our dataset examples into functions that will run pytest and log to our `LANGSMITH_TEST_SUITE`:\n",
    "\n",
    "```\n",
    "# Reference output key\n",
    "@pytest.mark.langsmith(output_keys=[\"criteria\"])\n",
    "# Variable names and a list of tuples with the test cases\n",
    "# Each test case is (email_input, email_name, criteria, expected_calls)\n",
    "@pytest.mark.parametrize(\"email_input,email_name,criteria,expected_calls\",create_response_test_cases())\n",
    "def test_response_criteria_evaluation(email_input, email_name, criteria, expected_calls):\n",
    "```\n",
    "\n",
    "We use LLM-as-judge with a grading schema:\n",
    "```\n",
    "class CriteriaGrade(BaseModel):\n",
    "    \"\"\"Score the response against specific criteria.\"\"\"\n",
    "    grade: bool = Field(description=\"Does the response meet the provided criteria?\")\n",
    "    justification: str = Field(description=\"The justification for the grade and score, including specific examples from the response.\")\n",
    "```\n",
    "\n",
    "\n",
    "We evaluate the agent response relative to the criteria:\n",
    "```\n",
    "    # Evaluate against criteria\n",
    "    eval_result = criteria_eval_structured_llm.invoke([\n",
    "        {\"role\": \"system\",\n",
    "            \"content\": RESPONSE_CRITERIA_SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\",\n",
    "            \"content\": f\"\"\"\\n\\n Response criteria: {criteria} \\n\\n Assistant's response: \\n\\n {all_messages_str} \\n\\n Evaluate whether the assistant's response meets the criteria and provide justification for your evaluation.\"\"\"}\n",
    "    ])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca836fbf",
   "metadata": {},
   "source": [
    "Now let's take a look at this experiment in the LangSmith UI and look into what our agent did well, and what it could improve on.\n",
    "\n",
    "#### Getting Results\n",
    "\n",
    "We can also get the results of the evaluation by reading the tracing project associated with our experiment. This is great for creating custom visualizations of our agent's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b655f8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# TODO: Copy your experiment name here\n",
    "experiment_name = \"email_assistant:8286b3b8\"\n",
    "# Set this to load expt results\n",
    "load_expt = False\n",
    "if load_expt:\n",
    "    email_assistant_experiment_results = client.read_project(project_name=experiment_name, include_stats=True)\n",
    "    print(\"Latency p50:\", email_assistant_experiment_results.latency_p50)\n",
    "    print(\"Latency p99:\", email_assistant_experiment_results.latency_p99)\n",
    "    print(\"Token Usage:\", email_assistant_experiment_results.total_tokens)\n",
    "    print(\"Feedback Stats:\", email_assistant_experiment_results.feedback_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccdfaa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
